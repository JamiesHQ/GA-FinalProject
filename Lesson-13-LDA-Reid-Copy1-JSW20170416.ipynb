{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Latent Dirichlet Allocation\n",
    "\n",
    "+ Most commonly used in natural language processing\n",
    "+ Sometimes as an end in and of itself\n",
    "+ Sometimes as a variable reduction technique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Simple Example of LDA in NLP\n",
    "\n",
    "Stolen from: http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-topics-extraction-with-nmf-lda-py\n",
    "\n",
    "+ Authors: \n",
    "    + Olivier Grisel <olivier.grisel@ensta.org>\n",
    "    + Lars Buitinck\n",
    "    + Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
    "+ License: BSD 3 clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### This code defines a custom function that we'll use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### This code loads the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 0.096s.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "df = pd.read_csv('issue_comments_jupyter_copy.csv')\n",
    "df['org'] = df['org'].astype('str')\n",
    "df['repo'] = df['repo'].astype('str')\n",
    "df['comments'] = df['comments'].astype('str')\n",
    "df['user'] = df['user'].astype('str')\n",
    "\n",
    "data_samples = df.comments[:n_samples]\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'same issue\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 0.128s.\n"
     ]
    }
   ],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.681s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_example = lda.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (10, 2000), indices imply (1, 2000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-38ecb57082bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"comments\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jamiew/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 297\u001b[0;31m                                          copy=copy)\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamiew/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_init_ndarray\u001b[0;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_possibly_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamiew/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4254\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4255\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4256\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamiew/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   4231\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4232\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[0;32m-> 4233\u001b[0;31m         passed, implied))\n\u001b[0m\u001b[1;32m   4234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (10, 2000), indices imply (1, 2000)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(X_example, columns = [\"comments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "kernel file ipython jupyter py\n",
      "Topic #1:\n",
      "github com https jupyter ellisonbg\n",
      "Topic #2:\n",
      "think like kernel just things\n",
      "Topic #3:\n",
      "bash process setsid subprocess setpgrp\n",
      "Topic #4:\n",
      "https com assets png cloud\n",
      "Topic #5:\n",
      "pr use issue logo thanks\n",
      "Topic #6:\n",
      "thanks page looks great file\n",
      "Topic #7:\n",
      "jupyter docker image images demo\n",
      "Topic #8:\n",
      "message ipython js comm ll\n",
      "Topic #9:\n",
      "optional install str self function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### In class assignment\n",
    "\n",
    "+ load in the training set (done for you below)\n",
    "+ re-run LDA and use topics as input for model\n",
    "+ Predict categories using some multinomial classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'), \n",
    "                            subset=\"train\")\n",
    "\n",
    "data = dataset.data\n",
    "\n",
    "y = dataset.target\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.unique(y, return_counts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf_vectorizer.fit(data)\n",
    "\n",
    "tf = tf_vectorizer.transform(data)\n",
    "\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=20, max_iter=50,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = lda.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'), \n",
    "                            subset=\"test\")\n",
    "\n",
    "testdata = test.data\n",
    "\n",
    "y_test = test.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier()\n",
    "\n",
    "clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "gs = GridSearchCV(estimator = RandomForestClassifier(), \n",
    "                 param_grid = {'n_estimators':np.arange(10, 21, 1)}, \n",
    "                 cv = KFold(n_splits=5))\n",
    "\n",
    "gs.fit(X, y)\n",
    "\n",
    "algo = gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_test = tf_vectorizer.transform(testdata)\n",
    "X_test = lda.transform(X_test)\n",
    "\n",
    "pred = clf2.predict(X_test)\n",
    "metrics.f1_score(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "algo.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### In class assignment:\n",
    "\n",
    "+ I'll divide you into 3 segments\n",
    "+ Each segment generates 100 sentences on the *same topic*\n",
    "+ Save as a JSON and send to me\n",
    "+ We'll run them through LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "CLASSLIST = [\"My favorite type of food is tacos, but it used to be fried chicken.\", \"My favorite type of taco is al pastor.\", \"My favorite mexican resturant is El Rancho.\", \"I also like all the resturants in my immediate neighborhood.\", \"Corn dogs are quite nice as well however my friends make fun of me\", \"Yo dog I love dog, but not like the food\", \"Sup hot stuff, you like hot food or cold food\", \"I raise chickens in my farm that I dont eat\", \"Sometimes I go fishing with my father\", \"Working at the food bank is very fulfilling to me\", \"If I eat too much Im not going to feel like drinking\", \"The breweries in San Diego are plentiful\", \"The food in San Deigo are not as good as the stuff in SF\", \"LA has really solid mexican food which I love\", \"Im pretty hungry right now, where should we grab lunch?\", \"Is dinner going to be taken care of at the Reynold's house?\", \"If I pay for breakfast will you cover lunch or dinner babe?\", \"Fast Food is not good for health\", \"Indian food is spicy\", \"I like Thai food\", \"There are two new restaurants opened around the block\", \"Can I get this sweet dish?\", \"McBurger has 3000 calories\", \"Nuts are good for health\", \"Vegetables are bad\", \"Cheese cake is good\", \"He ate all the fried food\", \"In istanbul, a burger cost $30\", \"The new hotel chain offers free buffet for 2 days\", \"Can I get a diet coke?\", \"How to cook fiesta salsa?\", \"These fries are tasty but bad for health\", \"This chinese restaurant serves the best soup\", \"Please order a pizza for me?\", \"Dinner is ready\", \"Doing breakfast is good for health\", \"Please dont throw extra food, donate it to someone hungry\", \"chocolate chip cookies and best fresh from the oven.\", \"pumpkin pie is a good dessert for the fall season\", \"vegtables are an important part of any diet\", \"fruit is a healthy way to suffice your sweet tooth\", \"eggs are a filling way eat breakfast\", \"soda is a necessary evil.\", \"philz coffee is a great way to start your morning\", \"after making a big dinner with several courses, at least there are leftovers.\", \"turnkey is a great type of meat\", \"hot sauce makes everything better.\", \"hot dogs and garlic fries are best when watching a giants baseball game.\", \"I like ketchup more than mustard\", \"I wish a had a few more cook books.\", \"The worst part of cooking is cleaning the pots and pans afterwards.\", \"I had cereal with a banana every morning before school as a kid.\", \"Avocado is my favorite type of vegtable.\", \"I try to avoid fast food restaurants as much as possible.\", \"shrimp scampi is one of my all time favorite dishes.\", \"cooking is something I hope to do more of later in life.\", \"salmon is a great type of food\", \"You should eat well, but not like Charles Barkley well.\", \"There are like 17 cooking shows. All of them seem to be related to Top Chef.\", \"Guy Fearri is not a chef so much as the lead from Smashmouth pretending to be a chef.\", \"Salt is not a food. But it goes well on food.\", \"Vegetarians who still eat fish are not vegetarians. They are just against eating things that have eyes.\", \"Vegans are basically food Taliban. Do not make me feel bad because I have good things in my life.\", \"They say cows shitting causes global warming. That means we should eat less cows. Maybe more veal though. What is the shit to meat produced ratio where we can still enjoy meat, but not destroy the only planet we have.\", \"My mother said pre-heat the oven. Instead I turned on the microwave.\", \"Turkey is the worst of the bird dishes.\", \"Dog is a food someplaces.\", \"To make rice, you just get rice, and then add water.\", \"Food Trucks are not made of food.\", \"Instagram is mostly a forum for posting food photos. ALso for Smirnoff ICe ads.\", \"Pasta is a delicacy.\", \"I refused to believe that gushers are a food.\", \"If you travel exclusively for local dishes, you have too much money.\", \"Happiness: a good bank account, a good cook, and a good digestion.\", \"Food Porn and Porn Food are not the same thing, and you should google only one.\", \"France thinks it has the best food in Europe, but really Italy does. In Asia, Thailand is to France, as Vietnam is to Italy. I will not negotiate on this.\"]\n",
    "\n",
    "sports = {\"Food\": CLASSLIST}\n",
    "\n",
    "import json\n",
    "\n",
    "with open('Food.json', 'w') as fp:\n",
    "    json.dump(sports, fp, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "travel = {\"Travel\":travellist}\n",
    "\n",
    "### JSON save:\n",
    "\n",
    "import json\n",
    "with open('Travel.json', 'w') as fp:\n",
    "    json.dump(travel, fp, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import from JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Here is where we import our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#This code imports a json of ALL viable glooko codes - before random selection\n",
    "\n",
    "import json\n",
    "with open('Food.json', 'r') as fp:\n",
    "    food = json.load(fp)\n",
    "\n",
    "with open('sports.json', 'r') as fp:\n",
    "    sports = json.load(fp)\n",
    "    \n",
    "with open('travel.json', 'r') as fp:\n",
    "    travel = json.load(fp)\n",
    "\n",
    "\n",
    "sentencelist = []\n",
    "\n",
    "sentencelist.extend(food['Food'])\n",
    "sentencelist.extend(sports['Sports'])\n",
    "sentencelist.extend(travel['Travel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### I'm using this code to create an outcome variable, \n",
    "\n",
    "+ so we can test our topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "y.extend([0]*len(food['Food']))\n",
    "y.extend([1]*len(sports['Sports']))\n",
    "y.extend([2]*len(travel['Travel']))\n",
    "\n",
    "label = []\n",
    "label.extend([\"Food\"]*len(food['Food']))\n",
    "label.extend([\"Sports\"]*len(sports['Sports']))\n",
    "label.extend([\"Travel\"]*len(travel['Travel']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### This organizes everything into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"y\":y, \"sentence\":sentencelist, \"label\":label})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### This splits our sentences and outcome var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Preprocessing! \n",
    "\n",
    "+ Here is the count vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 0.016s.\n"
     ]
    }
   ],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=10000,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf_vectorizer.fit(sentencelist)\n",
    "\n",
    "X = tf_vectorizer.transform(sentencelist)\n",
    "\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define the LDA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=3, max_iter=50,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=0.,\n",
    "                                random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=0.0,\n",
       "             max_doc_update_iter=100, max_iter=50, mean_change_tol=0.001,\n",
       "             n_jobs=1, n_topics=3, perp_tol=0.1, random_state=0,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06681848,  0.08079847,  0.85238305],\n",
       "       [ 0.11134396,  0.75357425,  0.13508179],\n",
       "       [ 0.11151966,  0.76358129,  0.12489904],\n",
       "       [ 0.16675077,  0.16678902,  0.66646021],\n",
       "       [ 0.8749538 ,  0.06928255,  0.05576365],\n",
       "       [ 0.0563297 ,  0.05568371,  0.88798659],\n",
       "       [ 0.04885048,  0.04771827,  0.90343125],\n",
       "       [ 0.829315  ,  0.08508571,  0.08559929],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.1113184 ,  0.11142213,  0.77725948],\n",
       "       [ 0.05938718,  0.0585844 ,  0.88202842],\n",
       "       [ 0.11133115,  0.11758495,  0.7710839 ],\n",
       "       [ 0.06781712,  0.06995786,  0.86222501],\n",
       "       [ 0.05641614,  0.05778286,  0.885801  ],\n",
       "       [ 0.06277123,  0.05801711,  0.87921165],\n",
       "       [ 0.08539285,  0.08616942,  0.82843773],\n",
       "       [ 0.85080342,  0.07051841,  0.07867817],\n",
       "       [ 0.06681021,  0.55686836,  0.37632143],\n",
       "       [ 0.16670708,  0.16685669,  0.66643623],\n",
       "       [ 0.11115031,  0.11120946,  0.77764022],\n",
       "       [ 0.0669114 ,  0.7465839 ,  0.18650471],\n",
       "       [ 0.16701965,  0.66599755,  0.1669828 ],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.11128304,  0.74677276,  0.1419442 ],\n",
       "       [ 0.16698663,  0.66600965,  0.16700372],\n",
       "       [ 0.11135196,  0.74641422,  0.14223382],\n",
       "       [ 0.08876009,  0.08375089,  0.82748902],\n",
       "       [ 0.16729464,  0.16747892,  0.66522644],\n",
       "       [ 0.44273775,  0.06751014,  0.48975211],\n",
       "       [ 0.16730225,  0.16748988,  0.66520788],\n",
       "       [ 0.16707354,  0.16719122,  0.66573524],\n",
       "       [ 0.08689918,  0.82951287,  0.08358796],\n",
       "       [ 0.66276371,  0.16688355,  0.17035273],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.18253376,  0.19115283,  0.62631341],\n",
       "       [ 0.45962675,  0.45584714,  0.08452611],\n",
       "       [ 0.32241475,  0.08382268,  0.59376257],\n",
       "       [ 0.40032412,  0.1117316 ,  0.48794427],\n",
       "       [ 0.11134405,  0.11610205,  0.7725539 ],\n",
       "       [ 0.16730225,  0.16748988,  0.66520788],\n",
       "       [ 0.35113467,  0.53183117,  0.11703416],\n",
       "       [ 0.82737913,  0.08582475,  0.08679612],\n",
       "       [ 0.167137  ,  0.66569745,  0.16716554],\n",
       "       [ 0.08118758,  0.0764871 ,  0.84232532],\n",
       "       [ 0.08664148,  0.82166595,  0.09169256],\n",
       "       [ 0.09718653,  0.08714852,  0.81566495],\n",
       "       [ 0.09167627,  0.09109795,  0.81722578],\n",
       "       [ 0.91713253,  0.03836815,  0.04449931],\n",
       "       [ 0.16675077,  0.16678902,  0.66646021],\n",
       "       [ 0.16707354,  0.16719122,  0.66573524],\n",
       "       [ 0.11127357,  0.77743805,  0.11128838],\n",
       "       [ 0.09946118,  0.09505015,  0.80548867],\n",
       "       [ 0.11134396,  0.75357425,  0.13508179],\n",
       "       [ 0.05569317,  0.72483159,  0.21947524],\n",
       "       [ 0.08344108,  0.83160673,  0.08495219],\n",
       "       [ 0.11131251,  0.77252604,  0.11616144],\n",
       "       [ 0.08341972,  0.08676655,  0.82981372],\n",
       "       [ 0.07294689,  0.06860755,  0.85844556],\n",
       "       [ 0.1037365 ,  0.55701604,  0.33924746],\n",
       "       [ 0.76518536,  0.12320111,  0.11161352],\n",
       "       [ 0.08354538,  0.09039118,  0.82606343],\n",
       "       [ 0.08622988,  0.84347502,  0.0702951 ],\n",
       "       [ 0.04198515,  0.6938983 ,  0.26411655],\n",
       "       [ 0.90078347,  0.0482216 ,  0.05099493],\n",
       "       [ 0.08363231,  0.08652686,  0.82984083],\n",
       "       [ 0.11127394,  0.77742749,  0.11129857],\n",
       "       [ 0.11124986,  0.11133315,  0.77741699],\n",
       "       [ 0.09085145,  0.81533778,  0.09381077],\n",
       "       [ 0.11113656,  0.1112308 ,  0.77763264],\n",
       "       [ 0.08357842,  0.58207263,  0.33434895],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.16670708,  0.16685669,  0.66643623],\n",
       "       [ 0.11351155,  0.44099362,  0.44549483],\n",
       "       [ 0.0556441 ,  0.05842911,  0.88592679],\n",
       "       [ 0.08354968,  0.09082521,  0.82562511],\n",
       "       [ 0.04090944,  0.03346392,  0.92562664],\n",
       "       [ 0.67170721,  0.26001352,  0.06827927],\n",
       "       [ 0.82635845,  0.08998079,  0.08366076],\n",
       "       [ 0.76799995,  0.11673773,  0.11526232],\n",
       "       [ 0.09577609,  0.09290984,  0.81131408],\n",
       "       [ 0.66527528,  0.16744522,  0.1672795 ],\n",
       "       [ 0.08015591,  0.07189732,  0.84794677],\n",
       "       [ 0.04929727,  0.05593005,  0.89477268],\n",
       "       [ 0.16697756,  0.66408278,  0.16893966],\n",
       "       [ 0.05878676,  0.88074561,  0.06046763],\n",
       "       [ 0.82941796,  0.08708391,  0.08349813],\n",
       "       [ 0.11133326,  0.76598559,  0.12268114],\n",
       "       [ 0.88319868,  0.05580401,  0.06099731],\n",
       "       [ 0.10949324,  0.08380935,  0.80669741],\n",
       "       [ 0.16707067,  0.16718608,  0.66574325],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.77591914,  0.11132943,  0.11275143],\n",
       "       [ 0.05653411,  0.88473373,  0.05873215],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.49884581,  0.11156064,  0.38959355],\n",
       "       [ 0.16716226,  0.66565834,  0.1671794 ],\n",
       "       [ 0.06865272,  0.86448946,  0.06685783],\n",
       "       [ 0.66518555,  0.1674962 ,  0.16731825],\n",
       "       [ 0.08345619,  0.83308293,  0.08346088],\n",
       "       [ 0.0835758 ,  0.08766604,  0.82875816],\n",
       "       [ 0.9064787 ,  0.04958832,  0.04393298],\n",
       "       [ 0.08547192,  0.83101563,  0.08351246],\n",
       "       [ 0.08359308,  0.82876364,  0.08764328],\n",
       "       [ 0.16716177,  0.665669  ,  0.16716923],\n",
       "       [ 0.77336309,  0.11160524,  0.11503167],\n",
       "       [ 0.08360416,  0.09370563,  0.82269021],\n",
       "       [ 0.11178196,  0.11161884,  0.7765992 ],\n",
       "       [ 0.84432083,  0.06911269,  0.08656648],\n",
       "       [ 0.04945736,  0.90146072,  0.04908192],\n",
       "       [ 0.08364976,  0.08365647,  0.83269376],\n",
       "       [ 0.66572112,  0.16719451,  0.16708437],\n",
       "       [ 0.88862804,  0.05570554,  0.05566643],\n",
       "       [ 0.51529687,  0.11157278,  0.37313035],\n",
       "       [ 0.04778616,  0.04922862,  0.90298522],\n",
       "       [ 0.06679588,  0.86540852,  0.0677956 ],\n",
       "       [ 0.03415795,  0.03576909,  0.93007296],\n",
       "       [ 0.05568079,  0.05748125,  0.88683796],\n",
       "       [ 0.06684186,  0.86429236,  0.06886578],\n",
       "       [ 0.04176301,  0.91277695,  0.04546004],\n",
       "       [ 0.0433643 ,  0.91366805,  0.04296765],\n",
       "       [ 0.04426559,  0.59952761,  0.3562068 ],\n",
       "       [ 0.03878469,  0.03826529,  0.92295002],\n",
       "       [ 0.03903294,  0.92298223,  0.03798483],\n",
       "       [ 0.06741808,  0.22342208,  0.70915984],\n",
       "       [ 0.08427153,  0.08699648,  0.82873199],\n",
       "       [ 0.77730704,  0.11137428,  0.11131868],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.18574452,  0.64725342,  0.16700205],\n",
       "       [ 0.08354633,  0.08371285,  0.83274082],\n",
       "       [ 0.16690904,  0.1694884 ,  0.66360256],\n",
       "       [ 0.65404077,  0.17881955,  0.16713969],\n",
       "       [ 0.066804  ,  0.06990319,  0.86329281],\n",
       "       [ 0.06683526,  0.06815213,  0.86501261],\n",
       "       [ 0.08352528,  0.08357869,  0.83289603],\n",
       "       [ 0.58299236,  0.04888248,  0.36812517],\n",
       "       [ 0.93730005,  0.0315624 ,  0.03113755],\n",
       "       [ 0.49458935,  0.46708605,  0.0383246 ],\n",
       "       [ 0.93569711,  0.032209  ,  0.03209389],\n",
       "       [ 0.8663383 ,  0.06685386,  0.06680784],\n",
       "       [ 0.77683482,  0.11168733,  0.11147785],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.74038434,  0.23338922,  0.02622644],\n",
       "       [ 0.93286915,  0.03370324,  0.03342761],\n",
       "       [ 0.47289427,  0.06896972,  0.45813601],\n",
       "       [ 0.48979247,  0.42642111,  0.08378643],\n",
       "       [ 0.04416525,  0.91342393,  0.04241082],\n",
       "       [ 0.31840004,  0.61469407,  0.0669059 ],\n",
       "       [ 0.11266451,  0.12328326,  0.76405223],\n",
       "       [ 0.97213216,  0.01356047,  0.01430737],\n",
       "       [ 0.77695076,  0.1115734 ,  0.11147584],\n",
       "       [ 0.44936866,  0.06870498,  0.48192637],\n",
       "       [ 0.05740515,  0.05856806,  0.88402679],\n",
       "       [ 0.39373705,  0.27200999,  0.33425296],\n",
       "       [ 0.91557149,  0.04229828,  0.04213023],\n",
       "       [ 0.50723615,  0.02685233,  0.46591152],\n",
       "       [ 0.89476934,  0.05372175,  0.05150891],\n",
       "       [ 0.97212962,  0.01356353,  0.01430685],\n",
       "       [ 0.0582965 ,  0.55083758,  0.39086592],\n",
       "       [ 0.05913846,  0.05630454,  0.884557  ],\n",
       "       [ 0.66513686,  0.16741952,  0.16744362],\n",
       "       [ 0.12173216,  0.76688073,  0.11138711],\n",
       "       [ 0.08355015,  0.80907448,  0.10737536],\n",
       "       [ 0.86092116,  0.07112378,  0.06795506],\n",
       "       [ 0.32880659,  0.08608519,  0.58510822],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.66533624,  0.16741156,  0.16725219],\n",
       "       [ 0.82476599,  0.09019152,  0.0850425 ],\n",
       "       [ 0.86559967,  0.06682202,  0.0675783 ],\n",
       "       [ 0.55244811,  0.05574476,  0.39180712],\n",
       "       [ 0.05897636,  0.8853203 ,  0.05570334],\n",
       "       [ 0.06825917,  0.05579133,  0.87594951],\n",
       "       [ 0.06719209,  0.07549064,  0.85731727],\n",
       "       [ 0.64441031,  0.06685304,  0.28873665],\n",
       "       [ 0.52230018,  0.42046805,  0.05723177],\n",
       "       [ 0.44518396,  0.44349736,  0.11131868],\n",
       "       [ 0.58285211,  0.0557005 ,  0.36144739],\n",
       "       [ 0.08395123,  0.1017976 ,  0.81425118],\n",
       "       [ 0.77670163,  0.11158601,  0.11171236],\n",
       "       [ 0.8476753 ,  0.08543847,  0.06688623],\n",
       "       [ 0.05776327,  0.8784207 ,  0.06381603],\n",
       "       [ 0.04972899,  0.90005153,  0.05021947],\n",
       "       [ 0.89912311,  0.05087226,  0.05000464],\n",
       "       [ 0.06118023,  0.89325481,  0.04556496],\n",
       "       [ 0.77693228,  0.11158383,  0.11148388],\n",
       "       [ 0.81289097,  0.09888317,  0.08822586],\n",
       "       [ 0.09140157,  0.82492461,  0.08367382],\n",
       "       [ 0.8520429 ,  0.0783057 ,  0.06965139],\n",
       "       [ 0.06734967,  0.06807468,  0.86457566],\n",
       "       [ 0.11349621,  0.44125632,  0.44524747],\n",
       "       [ 0.08352338,  0.82534379,  0.09113283],\n",
       "       [ 0.08753415,  0.81348267,  0.09898318],\n",
       "       [ 0.08341593,  0.0850864 ,  0.83149767],\n",
       "       [ 0.08545111,  0.08366995,  0.83087894],\n",
       "       [ 0.4507823 ,  0.11187185,  0.43734586],\n",
       "       [ 0.77715038,  0.11143487,  0.11141476],\n",
       "       [ 0.88854379,  0.05563606,  0.05582015],\n",
       "       [ 0.77715877,  0.11145465,  0.11138658],\n",
       "       [ 0.16726155,  0.16743422,  0.66530423],\n",
       "       [ 0.66532943,  0.16741208,  0.16725848],\n",
       "       [ 0.82791974,  0.08376639,  0.08831387],\n",
       "       [ 0.87949956,  0.05612566,  0.06437478],\n",
       "       [ 0.77689306,  0.11157415,  0.11153279],\n",
       "       [ 0.91397998,  0.04244599,  0.04357403],\n",
       "       [ 0.66534354,  0.16740695,  0.16724951],\n",
       "       [ 0.06679886,  0.06848841,  0.86471273],\n",
       "       [ 0.05595618,  0.23557782,  0.708466  ],\n",
       "       [ 0.02856313,  0.94142088,  0.03001599],\n",
       "       [ 0.0714252 ,  0.86137955,  0.06719524],\n",
       "       [ 0.06777583,  0.86320739,  0.06901677],\n",
       "       [ 0.03944712,  0.05226915,  0.90828372],\n",
       "       [ 0.08699637,  0.82765884,  0.08534479],\n",
       "       [ 0.72460456,  0.22066852,  0.05472693],\n",
       "       [ 0.05654319,  0.0579424 ,  0.88551441],\n",
       "       [ 0.08351667,  0.08768895,  0.82879438],\n",
       "       [ 0.82541632,  0.08921395,  0.08536974],\n",
       "       [ 0.11539866,  0.75885796,  0.12574337],\n",
       "       [ 0.04643755,  0.91588299,  0.03767946],\n",
       "       [ 0.85546584,  0.07531392,  0.06922025],\n",
       "       [ 0.8611552 ,  0.07101511,  0.06782969],\n",
       "       [ 0.07009214,  0.86305962,  0.06684823],\n",
       "       [ 0.66581345,  0.16714315,  0.16704339],\n",
       "       [ 0.11188069,  0.76322036,  0.12489895],\n",
       "       [ 0.43494737,  0.45321106,  0.11184157],\n",
       "       [ 0.89388619,  0.04780351,  0.0583103 ],\n",
       "       [ 0.03230648,  0.03313635,  0.93455717],\n",
       "       [ 0.41652251,  0.06770701,  0.51577048],\n",
       "       [ 0.56564318,  0.30923817,  0.12511866],\n",
       "       [ 0.08857185,  0.08501981,  0.82640834],\n",
       "       [ 0.90918714,  0.04799781,  0.04281505],\n",
       "       [ 0.04892608,  0.10506992,  0.846004  ],\n",
       "       [ 0.82362015,  0.09280314,  0.08357671],\n",
       "       [ 0.37013599,  0.05680174,  0.57306227],\n",
       "       [ 0.02823163,  0.02844267,  0.9433257 ],\n",
       "       [ 0.03848224,  0.31508271,  0.64643505],\n",
       "       [ 0.07329883,  0.07609215,  0.85060903],\n",
       "       [ 0.06961575,  0.0669033 ,  0.86348094],\n",
       "       [ 0.76554147,  0.11176334,  0.12269519],\n",
       "       [ 0.04919209,  0.89859672,  0.0522112 ],\n",
       "       [ 0.16726333,  0.16743706,  0.6652996 ],\n",
       "       [ 0.84586092,  0.08710132,  0.06703776],\n",
       "       [ 0.83022087,  0.08608583,  0.0836933 ],\n",
       "       [ 0.06077092,  0.71881359,  0.22041549],\n",
       "       [ 0.16728237,  0.19441596,  0.63830167],\n",
       "       [ 0.04794673,  0.6610017 ,  0.29105157],\n",
       "       [ 0.11305133,  0.12808883,  0.75885984],\n",
       "       [ 0.58480902,  0.08364278,  0.3315482 ],\n",
       "       [ 0.1823557 ,  0.647332  ,  0.1703123 ],\n",
       "       [ 0.11360579,  0.43733328,  0.44906094],\n",
       "       [ 0.06705039,  0.06907738,  0.86387223]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docprobs = lda.transform(X)\n",
    "\n",
    "docprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "traveling way best ball tour\n",
      "Topic #1:\n",
      "island time travelers worst ringle\n",
      "Topic #2:\n",
      "food travel rsquo like great\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Need to split into training and testing!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(docprobs, y, test_size=0.10, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train the random forest classifier on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predy = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, predy, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
